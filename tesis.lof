\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {spanish}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Resultados y ratios obtenidos en la encuesta por GEM y ESAN. Fuente: \cite {cr_gestion2018emprend}\relax }}{15}{figure.caption.4}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Ratio de éxito de proyectos en Kickstarter desde 2009 hasta 2019 (Febrero). Fuente: \cite {cr_hustle2019successrate}\relax }}{17}{figure.caption.5}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Ejemplo de algoritmo de regresión. Fuente: \cite {bk_zambrano2018supnosup}\relax }}{29}{figure.caption.6}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Ejemplo de algoritmo de clasificación. Fuente: \cite {bk_zambrano2018supnosup}\relax }}{29}{figure.caption.6}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Algoritmo de K Vecinos más cercanos con pesos ponderados. Fuente: \cite {tec_sancho2018supnosup}\relax }}{30}{figure.caption.7}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Funcionamiento del algoritmo de K medias. Fuente: \cite {tec_sancho2018supnosup}\relax }}{31}{figure.caption.8}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Componentes del Aprendizaje por Refuerzo. Fuente: \cite {bk_sutton2018rl}\relax }}{32}{figure.caption.9}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Diferencia entre Aprendizaje Automático y Aprendizaje Profundo. Fuente: \cite {tec_cook2018deeplearning}\relax }}{33}{figure.caption.10}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Diagrama de los seis pasos básicos. Fuente: \cite {gl_microsoft2019datamining}\relax }}{34}{figure.caption.11}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Fases de la metodología CRISP-DM. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }}{35}{figure.caption.12}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Fases de la metodología SEMMA. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }}{36}{figure.caption.13}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Fases de la metodología KDD. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }}{37}{figure.caption.14}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Modelo para representar una neurona propuesto por McCulloch y Pitts (1943). Fuente: \cite {bk_russell2004intart}\relax }}{39}{figure.caption.16}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Nodos con funciones de activación umbral en forma de puertas lógicas. Fuente: \cite {bk_russell2004intart}\relax }}{40}{figure.caption.17}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Función de activación sigmoide. Fuente: \cite {pr_dorofki2012ann}\relax }}{40}{figure.caption.18}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces Ilustración del algoritmo gradiente descendiente. Fuente: \cite {tec_sancho2017descentgrad}\relax }}{41}{figure.caption.19}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces Actualización de pesos W con el algoritmo. Fuente: \cite {gl_iartificial2019descentgrad}\relax }}{42}{figure.caption.20}%
\contentsline {figure}{\numberline {2.16}{\ignorespaces Capa oculta simple MLP con propagación hacia atrás. Fuente: \cite {gl_iartificial2019descentgrad}\relax }}{42}{figure.caption.21}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Redes neuronales de ejemplo. Fuente: \cite {gl_ansrw2019backpropagation}\relax }}{43}{figure.caption.22}%
\contentsline {figure}{\numberline {2.18}{\ignorespaces Función de activación tangente hiperbólica. Fuente: \cite {pr_dorofki2012ann}\relax }}{44}{figure.caption.23}%
\contentsline {figure}{\numberline {2.19}{\ignorespaces Función de activación puramente lineal. Fuente: \cite {pr_dorofki2012ann}\relax }}{44}{figure.caption.24}%
\contentsline {figure}{\numberline {2.20}{\ignorespaces Función de activación Unidad Lineal Rectificada. Fuente: \cite {gl_mlfa2019redesneuronales}\relax }}{44}{figure.caption.25}%
\contentsline {figure}{\numberline {2.21}{\ignorespaces Ejemplo de perceptrón simple. Fuente: \cite {gl_calvo2017clasifrna}\relax }}{45}{figure.caption.26}%
\contentsline {figure}{\numberline {2.22}{\ignorespaces Ejemplo de perceptrón multicapa. Fuente: \cite {gl_calvo2017clasifrna}\relax }}{46}{figure.caption.27}%
\contentsline {figure}{\numberline {2.23}{\ignorespaces Ejemplo de red neuronal convolucional. Fuente: \cite {gl_calvo2017clasifrna}\relax }}{46}{figure.caption.28}%
\contentsline {figure}{\numberline {2.24}{\ignorespaces Modelo Neocognitron de Fukushima (1980). Fuente: \cite {tec_li2019cnn}\relax }}{47}{figure.caption.29}%
\contentsline {figure}{\numberline {2.25}{\ignorespaces Modelo LeNet-5 de LeCun (1998). Fuente: \cite {tec_li2019cnn}\relax }}{47}{figure.caption.29}%
\contentsline {figure}{\numberline {2.26}{\ignorespaces Ejecución de la convolución en una entrada. Fuente: \cite {tec_lopez2016cnnTF}\relax }}{48}{figure.caption.30}%
\contentsline {figure}{\numberline {2.27}{\ignorespaces Generación de una nueva imagen a partir de filtros. Fuente: \cite {tec_li2019cnn}\relax }}{48}{figure.caption.31}%
\contentsline {figure}{\numberline {2.28}{\ignorespaces Secuencia de varias capas convolucionales. Fuente: \cite {tec_li2019cnn}\relax }}{49}{figure.caption.32}%
\contentsline {figure}{\numberline {2.29}{\ignorespaces Extracción de características a partir de convoluciones. Fuente: \cite {tec_li2019cnn}\relax }}{49}{figure.caption.33}%
\contentsline {figure}{\numberline {2.30}{\ignorespaces Ejemplo de matriz de imagen de entrada y un filtro. Fuente: \cite {tec_prabhu2018cnn}\relax }}{50}{figure.caption.34}%
\contentsline {figure}{\numberline {2.31}{\ignorespaces Dimensiones de una entrada y un filtro. Fuente: \cite {tec_li2019cnn}\relax }}{50}{figure.caption.35}%
\contentsline {figure}{\numberline {2.32}{\ignorespaces Paso de 2 píxeles por parte de un filtro. Fuente: \cite {tec_prabhu2018cnn}\relax }}{50}{figure.caption.35}%
\contentsline {figure}{\numberline {2.33}{\ignorespaces Aplanado de matrices luego de agrupar la capa. Fuente: \cite {tec_prabhu2018cnn}\relax }}{51}{figure.caption.36}%
\contentsline {figure}{\numberline {2.34}{\ignorespaces Arquitectura completa de una CNN. Fuente: \cite {tec_prabhu2018cnn}\relax }}{52}{figure.caption.37}%
\contentsline {figure}{\numberline {2.35}{\ignorespaces Ejemplo de red neuronal recurrente. Fuente: \cite {gl_calvo2018rnn}\relax }}{52}{figure.caption.38}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Prueba de Figura\relax }}{59}{figure.caption.39}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Cronograma de actividades de la investigación. Fuente: Elaboración propia\relax }}{62}{figure.caption.40}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
