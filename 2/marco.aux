\relax 
\providecommand\hyper@newdestlabel[2]{}
\FN@pp@footnotehinttrue 
\@writefile{toc}{\contentsline {chapter}{\numberline {2}MARCO TEÓRICO}{23}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loequcaption}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Antecedentes de la investigación}{23}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Primer antecedente: «Supervised Learning Model For Kickstarter Campaigns With R Mining» \citep *{pr_kamath2018suplearn}}{23}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.1}Planteamiento del Problema y objetivo }{24}{subsubsection.2.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.2}Técnicas empleadas por los autores}{24}{subsubsection.2.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.3}Metodología empleada por los autores}{24}{subsubsection.2.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.4}Resultados obtenidos}{24}{subsubsection.2.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Segundo antecedente: «Predicting Success in Equity Crowdfunding» \citep *{pr_beckwith2016predcrowd}}{24}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.1}Planteamiento del Problema y objetivo }{24}{subsubsection.2.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.2}Técnicas empleadas por los autores}{24}{subsubsection.2.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.3}Metodología empleada por los autores}{24}{subsubsection.2.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.4}Resultados obtenidos}{24}{subsubsection.2.1.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Tercer antecedente: «Money Talks: A Predictive Model on Crowdfunding Success Using Project Description» \citep *{pr_zhou2018projectdesc}}{24}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.1}Planteamiento del Problema y objetivo }{25}{subsubsection.2.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.2}Técnicas empleadas por los autores}{25}{subsubsection.2.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.3}Metodología empleada por los autores}{25}{subsubsection.2.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.4}Resultados obtenidos}{25}{subsubsection.2.1.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Cuarto antecedente: «The Determinants of Crowdfunding Success: A Semantic Text Analytics Approach» \citep *{pr_yuan2016textanalytics}}{25}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.1}Planteamiento del Problema y objetivo }{25}{subsubsection.2.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.2}Técnicas empleadas por los autores}{25}{subsubsection.2.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.3}Metodología empleada por los autores}{25}{subsubsection.2.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.4}Resultados obtenidos}{25}{subsubsection.2.1.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Quinto antecedente: «Will your Project get the Green light? Predicting the success of crowdfunding campaigns» \citep *{pr_chen2015predcrowd}}{25}{subsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5.1}Planteamiento del Problema y objetivo }{26}{subsubsection.2.1.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5.2}Técnicas empleadas por los autores}{26}{subsubsection.2.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5.3}Metodología empleada por los autores}{26}{subsubsection.2.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5.4}Resultados obtenidos}{26}{subsubsection.2.1.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Sexto antecedente: «Project Success Prediction in Crowdfunding Environments» \citep *{pr_li2016predcrowd}}{26}{subsection.2.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6.1}Planteamiento del Problema y objetivo }{26}{subsubsection.2.1.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6.2}Técnicas empleadas por los autores}{26}{subsubsection.2.1.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6.3}Metodología empleada por los autores}{26}{subsubsection.2.1.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6.4}Resultados obtenidos}{26}{subsubsection.2.1.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.7}Séptimo antecedente: «Effect of Social Media Connectivity on Success of Crowdfunding Campaigns» \citep *{pr_kaur2017socmedcrowd}}{26}{subsection.2.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7.1}Planteamiento del Problema y objetivo}{26}{subsubsection.2.1.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7.2}Técnicas empleadas por los autores}{27}{subsubsection.2.1.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7.3}Metodología empleada por los autores}{27}{subsubsection.2.1.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7.4}Resultados obtenidos}{27}{subsubsection.2.1.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.8}Octavo antecedente: «Prediction of Crowdfunding Project Success with Deep Learning» \citep *{pr_yu2018deeplearning}}{28}{subsection.2.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.8.1}Planteamiento del Problema y objetivo}{28}{subsubsection.2.1.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.8.2}Técnicas empleadas por los autores}{28}{subsubsection.2.1.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.8.3}Metodología empleada por los autores}{28}{subsubsection.2.1.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.8.4}Resultados obtenidos}{29}{subsubsection.2.1.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.9}Noveno antecedente: «Estimating the Days to Success of Campaigns in Crowdfunding: A Deep Survival Perspective» \citep *{pr_jin2019dayssuccess}}{29}{subsection.2.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.9.1}Planteamiento del Problema y objetivo}{29}{subsubsection.2.1.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.9.2}Técnicas empleadas por los autores}{29}{subsubsection.2.1.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.9.3}Metodología empleada por los autores}{30}{subsubsection.2.1.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.9.4}Resultados obtenidos}{30}{subsubsection.2.1.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.10}Décimo antecedente: «Success Prediction on Crowdfunding with Multimodal Deep Learning» \citep *{pr_cheng2019deeplearning}}{30}{subsection.2.1.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.10.1}Planteamiento del Problema y objetivo}{30}{subsubsection.2.1.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.10.2}Técnicas empleadas por los autores}{31}{subsubsection.2.1.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.10.3}Metodología empleada por los autores}{31}{subsubsection.2.1.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.10.4}Resultados obtenidos}{31}{subsubsection.2.1.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Bases Teóricas}{32}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Inteligencia Artificial}{32}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Aprendizaje Automático}{34}{subsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Ejemplo de algoritmo de regresión. Fuente: \cite {bk_zambrano2018supnosup}\relax }}{35}{figure.caption.7}\protected@file@percent }
\newlabel{2:fig1}{{2.1}{35}{Ejemplo de algoritmo de regresión. Fuente: \cite {bk_zambrano2018supnosup}\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Ejemplo de algoritmo de clasificación. Fuente: \cite {bk_zambrano2018supnosup}\relax }}{35}{figure.caption.7}\protected@file@percent }
\newlabel{2:fig2}{{2.2}{35}{Ejemplo de algoritmo de clasificación. Fuente: \cite {bk_zambrano2018supnosup}\relax }{figure.caption.7}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.1}{\ignorespaces Cálculo de los pesos para el algoritmo K-NN mediante ponderación de sus distancias. Fuente: \cite {tec_sancho2018supnosup}}}{36}{equcaption.caption.8}\protected@file@percent }
\newlabel{eq:weights-KNN}{{2.1}{36}{Cálculo de los pesos para el algoritmo K-NN mediante ponderación de sus distancias. Fuente: \cite {tec_sancho2018supnosup}}{equcaption.caption.8}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.2}{\ignorespaces Fórmula alternativa del algoritmo K-NN mediante sumatoria de pesos. Fuente: \cite {tec_sancho2018supnosup}}}{36}{equcaption.caption.10}\protected@file@percent }
\newlabel{eq:weights-KNN_alt}{{2.2}{36}{Fórmula alternativa del algoritmo K-NN mediante sumatoria de pesos. Fuente: \cite {tec_sancho2018supnosup}}{equcaption.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Algoritmo de K Vecinos más cercanos con pesos ponderados. Fuente: \cite {tec_sancho2018supnosup}\relax }}{36}{figure.caption.12}\protected@file@percent }
\newlabel{2:fig3}{{2.3}{36}{Algoritmo de K Vecinos más cercanos con pesos ponderados. Fuente: \cite {tec_sancho2018supnosup}\relax }{figure.caption.12}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.3}{\ignorespaces Fórmula del algoritmo k-means. Fuente: \cite {tec_sancho2018supnosup}}}{37}{equcaption.caption.13}\protected@file@percent }
\newlabel{eq:k-means}{{2.3}{37}{Fórmula del algoritmo k-means. Fuente: \cite {tec_sancho2018supnosup}}{equcaption.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Funcionamiento del algoritmo de K medias. Fuente: \cite {tec_sancho2018supnosup}\relax }}{37}{figure.caption.15}\protected@file@percent }
\newlabel{2:fig4}{{2.4}{37}{Funcionamiento del algoritmo de K medias. Fuente: \cite {tec_sancho2018supnosup}\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Componentes del Aprendizaje por Refuerzo. Fuente: \cite {bk_sutton2018rl}\relax }}{38}{figure.caption.16}\protected@file@percent }
\newlabel{2:fig5}{{2.5}{38}{Componentes del Aprendizaje por Refuerzo. Fuente: \cite {bk_sutton2018rl}\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Aprendizaje Profundo}{38}{subsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Diferencia entre Aprendizaje Automático y Aprendizaje Profundo. Fuente: \cite {tec_cook2018deeplearning}\relax }}{39}{figure.caption.17}\protected@file@percent }
\newlabel{2:fig6}{{2.6}{39}{Diferencia entre Aprendizaje Automático y Aprendizaje Profundo. Fuente: \cite {tec_cook2018deeplearning}\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Modelo Predictivo}{39}{subsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Minería de Datos}{40}{subsection.2.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Diagrama de los seis pasos básicos. Fuente: \cite {gl_microsoft2019datamining}\relax }}{40}{figure.caption.18}\protected@file@percent }
\newlabel{2:fig7}{{2.7}{40}{Diagrama de los seis pasos básicos. Fuente: \cite {gl_microsoft2019datamining}\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Metodologías de Minería de Datos}{41}{subsection.2.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Fases de la metodología CRISP-DM. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }}{41}{figure.caption.19}\protected@file@percent }
\newlabel{2:fig8}{{2.8}{41}{Fases de la metodología CRISP-DM. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Fases de la metodología SEMMA. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }}{42}{figure.caption.20}\protected@file@percent }
\newlabel{2:fig9}{{2.9}{42}{Fases de la metodología SEMMA. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Fases de la metodología KDD. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }}{43}{figure.caption.21}\protected@file@percent }
\newlabel{2:fig10}{{2.10}{43}{Fases de la metodología KDD. Fuente: \cite {tec_braulio2015metodologiasdm}\relax }{figure.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Cuadro comparativo entre características de las tres metodologías. Fuente: \cite {tec_shafique2014dmmodels}\relax }}{44}{table.caption.22}\protected@file@percent }
\newlabel{2:table1}{{2.1}{44}{Cuadro comparativo entre características de las tres metodologías. Fuente: \cite {tec_shafique2014dmmodels}\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}Técnicas de Minería de Datos}{44}{subsection.2.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Modelo para representar una neurona propuesto por McCulloch y Pitts (1943). Fuente: \cite {bk_russell2004intart}\relax }}{45}{figure.caption.23}\protected@file@percent }
\newlabel{2:fig11}{{2.11}{45}{Modelo para representar una neurona propuesto por McCulloch y Pitts (1943). Fuente: \cite {bk_russell2004intart}\relax }{figure.caption.23}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.4}{\ignorespaces Fórmula del cálculo del valor de un nodo i. Fuente: \cite {bk_russell2004intart}}}{46}{equcaption.caption.24}\protected@file@percent }
\newlabel{eq:nodo}{{2.4}{46}{Fórmula del cálculo del valor de un nodo i. Fuente: \cite {bk_russell2004intart}}{equcaption.caption.24}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.5}{\ignorespaces Fórmula de una función de activación g para la salida del nodo. Fuente: \cite {bk_russell2004intart}}}{46}{equcaption.caption.26}\protected@file@percent }
\newlabel{eq:activacion}{{2.5}{46}{Fórmula de una función de activación g para la salida del nodo. Fuente: \cite {bk_russell2004intart}}{equcaption.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Nodos con funciones de activación umbral en forma de puertas lógicas. Fuente: \cite {bk_russell2004intart}\relax }}{46}{figure.caption.28}\protected@file@percent }
\newlabel{2:fig12}{{2.12}{46}{Nodos con funciones de activación umbral en forma de puertas lógicas. Fuente: \cite {bk_russell2004intart}\relax }{figure.caption.28}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.6}{\ignorespaces Fórmula de la función de activación sigmoide. Fuente: \cite {pr_dorofki2012ann}}}{47}{equcaption.caption.29}\protected@file@percent }
\newlabel{eq:sigmoide}{{2.6}{47}{Fórmula de la función de activación sigmoide. Fuente: \cite {pr_dorofki2012ann}}{equcaption.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Función de activación sigmoide. Fuente: \cite {pr_dorofki2012ann}\relax }}{47}{figure.caption.31}\protected@file@percent }
\newlabel{2:fig13}{{2.13}{47}{Función de activación sigmoide. Fuente: \cite {pr_dorofki2012ann}\relax }{figure.caption.31}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.7}{\ignorespaces Fórmula de función de coste de una regresión logística. Fuente: \cite {gl_pardo_reglogcosto}}}{47}{equcaption.caption.32}\protected@file@percent }
\newlabel{eq:logistica}{{2.7}{47}{Fórmula de función de coste de una regresión logística. Fuente: \cite {gl_pardo_reglogcosto}}{equcaption.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Ilustración del algoritmo gradiente descendiente. Fuente: \cite {tec_sancho2017descentgrad}\relax }}{48}{figure.caption.34}\protected@file@percent }
\newlabel{2:fig14}{{2.14}{48}{Ilustración del algoritmo gradiente descendiente. Fuente: \cite {tec_sancho2017descentgrad}\relax }{figure.caption.34}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.8}{\ignorespaces Actualización de pesos W mediante gradiente descendiente. Fuente: \cite {gl_iartificial2019descentgrad}}}{49}{equcaption.caption.35}\protected@file@percent }
\newlabel{eq:w_descgrad}{{2.8}{49}{Actualización de pesos W mediante gradiente descendiente. Fuente: \cite {gl_iartificial2019descentgrad}}{equcaption.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Actualización de pesos W con el algoritmo. Fuente: \cite {gl_iartificial2019descentgrad}\relax }}{49}{figure.caption.37}\protected@file@percent }
\newlabel{2:fig15}{{2.15}{49}{Actualización de pesos W con el algoritmo. Fuente: \cite {gl_iartificial2019descentgrad}\relax }{figure.caption.37}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.9}{\ignorespaces Fórmula del algoritmo de propagación hacia atrás. Fuente: \cite {tec_bertona2005algevol}}}{50}{equcaption.caption.38}\protected@file@percent }
\newlabel{eq:backpropagation}{{2.9}{50}{Fórmula del algoritmo de propagación hacia atrás. Fuente: \cite {tec_bertona2005algevol}}{equcaption.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Capa oculta simple MLP con propagación hacia atrás. Fuente: \cite {gl_iartificial2019descentgrad}\relax }}{50}{figure.caption.40}\protected@file@percent }
\newlabel{2:fig16}{{2.16}{50}{Capa oculta simple MLP con propagación hacia atrás. Fuente: \cite {gl_iartificial2019descentgrad}\relax }{figure.caption.40}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.10}{\ignorespaces Cálculo del error cometido en una red neuronal. Fuente: \cite {tec_viera2013backpropexplain}}}{50}{equcaption.caption.42}\protected@file@percent }
\newlabel{eq:rnaerror}{{2.10}{50}{Cálculo del error cometido en una red neuronal. Fuente: \cite {tec_viera2013backpropexplain}}{equcaption.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Redes neuronales de ejemplo. Fuente: \cite {gl_ansrw2019backpropagation}\relax }}{51}{figure.caption.41}\protected@file@percent }
\newlabel{2:fig17}{{2.17}{51}{Redes neuronales de ejemplo. Fuente: \cite {gl_ansrw2019backpropagation}\relax }{figure.caption.41}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.11}{\ignorespaces Actualización de pesos mediante propagación hacia atrás. Fuente: \cite {tec_viera2013backpropexplain}}}{51}{equcaption.caption.44}\protected@file@percent }
\newlabel{eq:updateweightsrna}{{2.11}{51}{Actualización de pesos mediante propagación hacia atrás. Fuente: \cite {tec_viera2013backpropexplain}}{equcaption.caption.44}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.12}{\ignorespaces Cálculo de errores de nodos usando pesos actualizados. Fuente: \cite {tec_viera2013backpropexplain}}}{51}{equcaption.caption.46}\protected@file@percent }
\newlabel{eq:errornodorna}{{2.12}{51}{Cálculo de errores de nodos usando pesos actualizados. Fuente: \cite {tec_viera2013backpropexplain}}{equcaption.caption.46}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.13}{\ignorespaces Fórmula de la función de activación tangente hiperbólica. Fuente: \cite {pr_dorofki2012ann}}}{52}{equcaption.caption.48}\protected@file@percent }
\newlabel{eq:tansig}{{2.13}{52}{Fórmula de la función de activación tangente hiperbólica. Fuente: \cite {pr_dorofki2012ann}}{equcaption.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Función de activación tangente hiperbólica. Fuente: \cite {pr_dorofki2012ann}\relax }}{52}{figure.caption.50}\protected@file@percent }
\newlabel{2:fig18}{{2.18}{52}{Función de activación tangente hiperbólica. Fuente: \cite {pr_dorofki2012ann}\relax }{figure.caption.50}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.14}{\ignorespaces Fórmula de la función de activación puramente lineal. Fuente: \cite {pr_dorofki2012ann}}}{52}{equcaption.caption.51}\protected@file@percent }
\newlabel{eq:purelin}{{2.14}{52}{Fórmula de la función de activación puramente lineal. Fuente: \cite {pr_dorofki2012ann}}{equcaption.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces Función de activación puramente lineal. Fuente: \cite {pr_dorofki2012ann}\relax }}{53}{figure.caption.53}\protected@file@percent }
\newlabel{2:fig19}{{2.19}{53}{Función de activación puramente lineal. Fuente: \cite {pr_dorofki2012ann}\relax }{figure.caption.53}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.15}{\ignorespaces Fórmula de la función de activación ReLU. Fuente: \cite {gl_calvo2018activrna}}}{53}{equcaption.caption.54}\protected@file@percent }
\newlabel{eq:relu}{{2.15}{53}{Fórmula de la función de activación ReLU. Fuente: \cite {gl_calvo2018activrna}}{equcaption.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces Función de activación Unidad Lineal Rectificada. Fuente: \cite {gl_mlfa2019redesneuronales}\relax }}{54}{figure.caption.56}\protected@file@percent }
\newlabel{2:fig20}{{2.20}{54}{Función de activación Unidad Lineal Rectificada. Fuente: \cite {gl_mlfa2019redesneuronales}\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces Ejemplo de perceptrón simple. Fuente: \cite {gl_calvo2017clasifrna}\relax }}{54}{figure.caption.57}\protected@file@percent }
\newlabel{2:fig21}{{2.21}{54}{Ejemplo de perceptrón simple. Fuente: \cite {gl_calvo2017clasifrna}\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces Ejemplo de perceptrón multicapa. Fuente: \cite {gl_calvo2017clasifrna}\relax }}{55}{figure.caption.58}\protected@file@percent }
\newlabel{2:fig22}{{2.22}{55}{Ejemplo de perceptrón multicapa. Fuente: \cite {gl_calvo2017clasifrna}\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces Ejemplo de red neuronal convolucional. Fuente: \cite {gl_calvo2017clasifrna}\relax }}{55}{figure.caption.59}\protected@file@percent }
\newlabel{2:fig23}{{2.23}{55}{Ejemplo de red neuronal convolucional. Fuente: \cite {gl_calvo2017clasifrna}\relax }{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces Modelo Neocognitron de Fukushima (1980). Fuente: \cite {tec_li2019cnn}\relax }}{56}{figure.caption.60}\protected@file@percent }
\newlabel{2:fig24}{{2.24}{56}{Modelo Neocognitron de Fukushima (1980). Fuente: \cite {tec_li2019cnn}\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces Modelo LeNet-5 de LeCun (1998). Fuente: \cite {tec_li2019cnn}\relax }}{56}{figure.caption.60}\protected@file@percent }
\newlabel{2:fig25}{{2.25}{56}{Modelo LeNet-5 de LeCun (1998). Fuente: \cite {tec_li2019cnn}\relax }{figure.caption.60}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.16}{\ignorespaces Fórmula matemática de la convolución. Fuente: \cite {tec_figueroa_convolucion}}}{56}{equcaption.caption.61}\protected@file@percent }
\newlabel{eq:convolution}{{2.16}{56}{Fórmula matemática de la convolución. Fuente: \cite {tec_figueroa_convolucion}}{equcaption.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces Ejecución de la convolución en una entrada. Fuente: \cite {tec_lopez2016cnnTF}\relax }}{57}{figure.caption.63}\protected@file@percent }
\newlabel{2:fig26}{{2.26}{57}{Ejecución de la convolución en una entrada. Fuente: \cite {tec_lopez2016cnnTF}\relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces Generación de una nueva imagen a partir de filtros. Fuente: \cite {tec_li2019cnn}\relax }}{57}{figure.caption.64}\protected@file@percent }
\newlabel{2:fig27}{{2.27}{57}{Generación de una nueva imagen a partir de filtros. Fuente: \cite {tec_li2019cnn}\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.28}{\ignorespaces Secuencia de varias capas convolucionales. Fuente: \cite {tec_li2019cnn}\relax }}{58}{figure.caption.65}\protected@file@percent }
\newlabel{2:fig28}{{2.28}{58}{Secuencia de varias capas convolucionales. Fuente: \cite {tec_li2019cnn}\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.29}{\ignorespaces Extracción de características a partir de convoluciones. Fuente: \cite {tec_li2019cnn}\relax }}{58}{figure.caption.66}\protected@file@percent }
\newlabel{2:fig29}{{2.29}{58}{Extracción de características a partir de convoluciones. Fuente: \cite {tec_li2019cnn}\relax }{figure.caption.66}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.17}{\ignorespaces Cálculo del volumen del mapa de activación. Fuente: \cite {tec_prabhu2018cnn}}}{58}{equcaption.caption.67}\protected@file@percent }
\newlabel{eq:mapaact}{{2.17}{58}{Cálculo del volumen del mapa de activación. Fuente: \cite {tec_prabhu2018cnn}}{equcaption.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.30}{\ignorespaces Ejemplo de matriz de imagen de entrada y un filtro. Fuente: \cite {tec_prabhu2018cnn}\relax }}{59}{figure.caption.69}\protected@file@percent }
\newlabel{2:fig30}{{2.30}{59}{Ejemplo de matriz de imagen de entrada y un filtro. Fuente: \cite {tec_prabhu2018cnn}\relax }{figure.caption.69}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.18}{\ignorespaces Cálculo del tamaño de la imagen reducida. Fuente: \cite {tec_li2019cnn}}}{59}{equcaption.caption.70}\protected@file@percent }
\newlabel{eq:outputconv}{{2.18}{59}{Cálculo del tamaño de la imagen reducida. Fuente: \cite {tec_li2019cnn}}{equcaption.caption.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.31}{\ignorespaces Dimensiones de una entrada y un filtro. Fuente: \cite {tec_li2019cnn}\relax }}{60}{figure.caption.72}\protected@file@percent }
\newlabel{2:fig31}{{2.31}{60}{Dimensiones de una entrada y un filtro. Fuente: \cite {tec_li2019cnn}\relax }{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.32}{\ignorespaces Paso de 2 píxeles por parte de un filtro. Fuente: \cite {tec_prabhu2018cnn}\relax }}{60}{figure.caption.72}\protected@file@percent }
\newlabel{2:fig32}{{2.32}{60}{Paso de 2 píxeles por parte de un filtro. Fuente: \cite {tec_prabhu2018cnn}\relax }{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.33}{\ignorespaces Aplanado de matrices luego de agrupar la capa. Fuente: \cite {tec_prabhu2018cnn}\relax }}{61}{figure.caption.73}\protected@file@percent }
\newlabel{2:fig33}{{2.33}{61}{Aplanado de matrices luego de agrupar la capa. Fuente: \cite {tec_prabhu2018cnn}\relax }{figure.caption.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.34}{\ignorespaces Arquitectura completa de una CNN. Fuente: \cite {tec_prabhu2018cnn}\relax }}{61}{figure.caption.74}\protected@file@percent }
\newlabel{2:fig34}{{2.34}{61}{Arquitectura completa de una CNN. Fuente: \cite {tec_prabhu2018cnn}\relax }{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.35}{\ignorespaces Ejemplo de red neuronal recurrente. Fuente: \cite {gl_calvo2018rnn}\relax }}{62}{figure.caption.75}\protected@file@percent }
\newlabel{2:fig35}{{2.35}{62}{Ejemplo de red neuronal recurrente. Fuente: \cite {gl_calvo2018rnn}\relax }{figure.caption.75}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.36}{\ignorespaces Hiperplano con dos clases separadas por una distancia m. Fuente: \cite {tec_betancourt2005svm}\relax }}{62}{figure.caption.76}\protected@file@percent }
\newlabel{2:fig36}{{2.36}{62}{Hiperplano con dos clases separadas por una distancia m. Fuente: \cite {tec_betancourt2005svm}\relax }{figure.caption.76}{}}
\@writefile{loequcaption}{\contentsline {equcaption}{\numberline {2.19}{\ignorespaces Ecuación del hiperplano para clasificar dos clases. Fuente: \cite {tec_betancourt2005svm}}}{62}{equcaption.caption.78}\protected@file@percent }
\newlabel{eq:hiperplano}{{2.19}{62}{Ecuación del hiperplano para clasificar dos clases. Fuente: \cite {tec_betancourt2005svm}}{equcaption.caption.78}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.37}{\ignorespaces Ejemplo de caso linealmente separable. Fuente: \cite {tec_betancourt2005svm}\relax }}{63}{figure.caption.77}\protected@file@percent }
\newlabel{2:fig37}{{2.37}{63}{Ejemplo de caso linealmente separable. Fuente: \cite {tec_betancourt2005svm}\relax }{figure.caption.77}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.38}{\ignorespaces Ejemplo de caso no linealmente separable. Fuente: \cite {tec_betancourt2005svm}\relax }}{63}{figure.caption.77}\protected@file@percent }
\newlabel{2:fig38}{{2.38}{63}{Ejemplo de caso no linealmente separable. Fuente: \cite {tec_betancourt2005svm}\relax }{figure.caption.77}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.39}{\ignorespaces Aplicación de un kernel para transformar el espacio de los datos. Fuente: \cite {tec_betancourt2005svm}\relax }}{63}{figure.caption.80}\protected@file@percent }
\newlabel{2:fig39}{{2.39}{63}{Aplicación de un kernel para transformar el espacio de los datos. Fuente: \cite {tec_betancourt2005svm}\relax }{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.40}{\ignorespaces Ejemplo del algoritmo de árbol de decisión. Fuente: \cite {bk_russell2004intart}\relax }}{64}{figure.caption.81}\protected@file@percent }
\newlabel{2:fig40}{{2.40}{64}{Ejemplo del algoritmo de árbol de decisión. Fuente: \cite {bk_russell2004intart}\relax }{figure.caption.81}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.8}Procesamiento del Lenguaje Natural}{64}{subsection.2.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Marco Conceptual}{65}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Crowdfunding}{65}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Kickstarter}{67}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Proyecto}{67}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Campaña}{68}{subsection.2.3.4}\protected@file@percent }
\FN@pp@footnotehinttrue 
\@setckpt{2/marco}{
\setcounter{page}{70}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{40}
\setcounter{table}{1}
\setcounter{lstnumber}{1}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{316}
\setcounter{maxnames}{2}
\setcounter{minnames}{1}
\setcounter{maxitems}{999}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{6}
\setcounter{maxextradate}{6}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{groupauthor}{0}
\setcounter{savedgroupauthor}{0}
\setcounter{narrator}{0}
\setcounter{savednarrator}{0}
\setcounter{execproducer}{0}
\setcounter{savedexecproducer}{0}
\setcounter{execdirector}{0}
\setcounter{savedexecdirector}{0}
\setcounter{with}{0}
\setcounter{savedwith}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{citation}{0}
\setcounter{savedcitation}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{0}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{89}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{pp@next@reset}{1}
\setcounter{@fnserial}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{nlinenum}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{COOL@strlen}{0}
\setcounter{COOL@strpointer}{0}
\setcounter{COOL@str@index}{0}
\setcounter{COOL@str@start}{0}
\setcounter{COOL@str@end}{0}
\setcounter{COOL@listlen}{0}
\setcounter{COOL@listpointer}{0}
\setcounter{COOL@intsum}{0}
\setcounter{COOL@register@ct}{0}
\setcounter{COOL@register@len}{0}
\setcounter{COOL@ct}{0}
\setcounter{COOL@ct@}{0}
\setcounter{COOL@multideriv}{0}
\setcounter{COOL@row}{0}
\setcounter{COOL@col}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{equcaption}{19}
\setcounter{loequcaptiondepth}{1}
\setcounter{lstlisting}{0}
\setcounter{section@level}{2}
}
